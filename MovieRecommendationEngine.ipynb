{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wjEmkE_qhFj4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import pickle\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset into train and test set\n",
    "The dataset was split into half to form a train and test split. Since it is essential to have half of each user’s rated movies in training and the other half as testing and we have a total of 138493 users, it was computationally infeasible to perform the split randomly for each user. Hence, the even rows in the dataset were included in the training set and the odd rows were included in the test set. Although not random, it ensures that half of each user’s rated movies are in the training set and the other half in the testing set since all rated movies for a particular user in the dataset are contiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 60347,
     "status": "ok",
     "timestamp": 1519288490993,
     "user": {
      "displayName": "Shreyas Mundhra",
      "photoUrl": "//lh6.googleusercontent.com/-NAxZtDWd8Qw/AAAAAAAAAAI/AAAAAAAAABM/wJAT8GNp7hg/s50-c-k-no/photo.jpg",
      "userId": "101017276597517313247"
     },
     "user_tz": 300
    },
    "id": "wQLiIwkw4d6w",
    "outputId": "93b8c525-a5cb-44fd-ae74-d1d991378844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total size of dataset: ', 20000263)\n",
      "('Training set size: ', 10000132)\n",
      "('Test set size: ', 10000131)\n"
     ]
    }
   ],
   "source": [
    "def createTestSet(df, splitFraction, seed):\n",
    "    return df.drop(df.sample(frac=splitFraction, random_state=seed).index)\n",
    "\n",
    "def splitDatasets(splitFraction):\n",
    "    df = pd.read_csv('ml-20m/ratings.csv')\n",
    "    print(\"Total size of dataset: \", len(df))\n",
    "\n",
    "    trainDf = df.iloc[[i for i in range(0,len(df),2)]]\n",
    "    testDf = df.iloc[[i for i in range(1,len(df),2)]]\n",
    "\n",
    "    print(\"Training set size: \", len(trainDf))\n",
    "    print(\"Test set size: \", len(testDf))\n",
    "\n",
    "    return trainDf, testDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDf, testDf = splitDatasets(splitFraction=0.5)\n",
    "trainDf.to_csv('processed/train.csv', index=False)\n",
    "testDf.to_csv('processed/test.csv', index=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Movie Dictionary from dataset\n",
    "Since the movie ids were not contiguous (unlike user ids), they had to be mapped to contiguous integers which can be used to index the columns of the rating matrix R and the rows of its factor W. This was done by finding the unique movie ids in the entire dataset and then mapping them to contiguous integers using a dictionary. This was stored as a pickle file so that the dictionary just needs to be computed once in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildMovieDict(df):\n",
    "    distinctMovies = df['movieId'].unique()\n",
    "    numMovies = len(distinctMovies)\n",
    "    movieDict = dict([(distinctMovies[i], i + 1) for i in range(0, numMovies)])\n",
    "    \n",
    "    with open('intermediate/movieDict.pkl', 'wb') as handle:\n",
    "        pickle.dump(movieDict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return movieDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ml-20m/ratings.csv')\n",
    "movieDict = buildMovieDict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building ratings matrix R from dataframe\n",
    "The next step was to implement a function to create the ratings matrix R from a dataset (train set or test set in this case). This was implemented as a sparse matrix in scipy due to the large dimensions of R and the sparsity of the observed ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "krk3wv0Eh-TA"
   },
   "outputs": [],
   "source": [
    "def buildRatingsMatrix(df, movieDict):\n",
    "    R = sps.coo_matrix((df['rating'], (df['userId'], df['movieId'].apply(lambda cell: movieDict[cell]))))\n",
    "    print(\"Rating Matrix shape: \", R.shape)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving factors of R\n",
    "The next step was to implement a function to save the factors V and W in a pickle file after the training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xTsDLuNJ603H"
   },
   "outputs": [],
   "source": [
    "def saveFactors(V, W):\n",
    "    with open('factors/V.pkl', 'wb') as handle:\n",
    "        pickle.dump(V, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('factors/W.pkl', 'wb') as handle:\n",
    "        pickle.dump(W, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing / Loading factors of R\n",
    "If the factors V and W are already stored in a pickle file, they are loaded from the file instead of randomly initializing V and W. This ensures that training can be resumed later and it does not need to start from scratch every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hy5TI-TciQZY"
   },
   "outputs": [],
   "source": [
    "def initFactors(numUsers, numMovies, rank):\n",
    "    V = np.random.randn(numUsers + 1, rank)\n",
    "    W = np.random.randn(numMovies + 1, rank)\n",
    "    \n",
    "    if(os.path.exists('factors/V.pkl')):\n",
    "        print(\"V exists\")\n",
    "        with open('factors/V.pkl', 'rb') as handle:\n",
    "            V = pickle.load(handle)\n",
    "    if(os.path.exists('factors/W.pkl')):\n",
    "        print(\"W exists\")\n",
    "        with open('factors/W.pkl', 'rb') as handle:\n",
    "            W = pickle.load(handle)\n",
    "            \n",
    "    return V, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GP0f7cqP7Oje"
   },
   "outputs": [],
   "source": [
    "def findCost(R, V, W, decay):\n",
    "    cost = np.sqrt(len(R.row)) * (findRMSE(R, V, W))\n",
    "    \n",
    "    squared_V_norm = np.linalg.norm(V)**2\n",
    "    squared_W_norm = np.linalg.norm(W)**2\n",
    "    \n",
    "    cost = cost + decay * (squared_V_norm + squared_W_norm)    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bstfyiW77Swi"
   },
   "outputs": [],
   "source": [
    "def findRMSE(R, V, W):\n",
    "    mse = 0\n",
    "    size = len(R.row)\n",
    "    \n",
    "    for row, col, r in itertools.izip(R.row, R.col, R.data):\n",
    "        if col >= len(W):\n",
    "            vw_T = 2.5\n",
    "        else:\n",
    "            v = V[row]\n",
    "            w = W[col]\n",
    "            vw_T = v.dot(w)\n",
    "        r_minus_vwT = (r - vw_T)        \n",
    "        mse = mse + r_minus_vwT**2\n",
    "    \n",
    "    rmse = np.sqrt(mse/size)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findMRR(R_test, testDf, V, W):\n",
    "    filteredDf = testDf[testDf['rating'] >= 3]\n",
    "    filteredTest = buildRatingsMatrix(filteredDf, movieDict).tolil()\n",
    "    \n",
    "    numUsers = R_test.shape[0] - 1\n",
    "    mrr = 0\n",
    "    count = 0\n",
    "    \n",
    "    for user in range(1, numUsers + 1):\n",
    "        if(user % 20000 == 0):\n",
    "            print(\"User id: \", user)\n",
    "            print(\"MRR: \", mrr/float(count))\n",
    "\n",
    "        v = V[user]\n",
    "        r_predicted = np.matmul(v, W.T).flatten()\n",
    "        \n",
    "        # appends two minimum ratings for the two movies present in test set but not in train set\n",
    "        # since those movies should have minimum chance of being recommended\n",
    "        r_predicted = np.append(r_predicted, r_predicted.min()-1)\n",
    "        r_predicted = np.append(r_predicted, r_predicted.min()-1)\n",
    "        \n",
    "        sortedIndices = np.argsort(-r_predicted)\n",
    "        indices_of_sortedIndices = filteredTest.rows[user]\n",
    "        \n",
    "        ranks = sortedIndices[indices_of_sortedIndices] + 1\n",
    "        inv_ranks = 1.0/ranks\n",
    "        \n",
    "        user_mrr = 0\n",
    "        \n",
    "        if len(inv_ranks.flatten()) > 0:\n",
    "            user_mrr = np.sum(inv_ranks)/float(len(inv_ranks.flatten()))\n",
    "            count = count + 1\n",
    "        \n",
    "        mrr = mrr + user_mrr\n",
    "        \n",
    "    mrr = mrr/float(count)\n",
    "    print(\"MRR: \", mrr)\n",
    "    return mrr      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "The main function for training using stochastic gradient descent with regularization. An entire pass of the training set is done in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pGiQE3uUiWti"
   },
   "outputs": [],
   "source": [
    "def train(R, learning_rate, decay, epochs, rank):\n",
    "    numUsers = R.shape[0] - 1\n",
    "    numMovies = R.shape[1] - 1\n",
    "    \n",
    "    # initialise/load V and W\n",
    "    V, W = initFactors(numUsers, numMovies, rank)\n",
    "        \n",
    "    try:\n",
    "        j = 0\n",
    "        \n",
    "        # train for multiple epochs\n",
    "        for i in range(0, epochs):\n",
    "            # iterate through all rated movies in R in each epoch\n",
    "            for row, col, r in itertools.izip(R.row, R.col, R.data):\n",
    "                if(j % 10000000 == 0):\n",
    "                    print(\"Iteration: \", (j + 1))\n",
    "\n",
    "                j = j + 1\n",
    "                \n",
    "                # find predicted rating for a single user-movie pair\n",
    "                v = V[row]\n",
    "                w = W[col]\n",
    "                vw_T = v.dot(w)\n",
    "                \n",
    "                # find difference between true rating and predicted rating of the user-movie pair\n",
    "                r_minus_vwT = r - vw_T\n",
    "\n",
    "                # update v and w with regularization using SGD for the user and movie\n",
    "                v_new = v + learning_rate * (2 * r_minus_vwT * w - 2 * decay * v)\n",
    "                w_new = w + learning_rate * (2 * r_minus_vwT * v - 2 * decay * w)\n",
    "\n",
    "                V[row] = v_new\n",
    "                W[col] = w_new\n",
    "\n",
    "        # find cost\n",
    "        cost = findCost(R, V, W, decay)\n",
    "        print(\"Cost: \", cost)\n",
    "        \n",
    "        # save V and W\n",
    "        saveFactors(V, W)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        # find cost\n",
    "        cost = findCost(R, V, W, decay)\n",
    "        print(\"Cost: \", cost)\n",
    "        \n",
    "        # save and return V and W\n",
    "        saveFactors(V, W)\n",
    "        return V, W\n",
    "\n",
    "    return V, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 14542,
     "status": "ok",
     "timestamp": 1519275518822,
     "user": {
      "displayName": "Shreyas Mundhra",
      "photoUrl": "//lh6.googleusercontent.com/-NAxZtDWd8Qw/AAAAAAAAAAI/AAAAAAAAABM/wJAT8GNp7hg/s50-c-k-no/photo.jpg",
      "userId": "101017276597517313247"
     },
     "user_tz": 300
    },
    "id": "_yAzzyJ5idne",
    "outputId": "36767e13-a38a-471a-f134-7a62584d0fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'userId', u'movieId', u'rating', u'timestamp'], dtype='object')\n",
      "10000132\n",
      "('Rating Matrix shape: ', (138494, 26743))\n"
     ]
    }
   ],
   "source": [
    "trainDf = pd.read_csv('processed/train.csv')\n",
    "with open('intermediate/movieDict.pkl', 'rb') as handle:\n",
    "    movieDict = pickle.load(handle)\n",
    "R = buildRatingsMatrix(trainDf, movieDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 606,
     "output_extras": [
      {
       "item_id": 30
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "dvKnpsRi9IpK",
    "outputId": "aed492f4-b2ed-4e17-ef9b-ec6308d0dce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V exists\n",
      "W exists\n",
      "('Iteration: ', 1)\n",
      "('Iteration: ', 10000001)\n",
      "('Cost: ', 36569.29635013777)\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "V, W = train(R, 0.02, 0.05, 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 4025,
     "status": "ok",
     "timestamp": 1519275531904,
     "user": {
      "displayName": "Shreyas Mundhra",
      "photoUrl": "//lh6.googleusercontent.com/-NAxZtDWd8Qw/AAAAAAAAAAI/AAAAAAAAABM/wJAT8GNp7hg/s50-c-k-no/photo.jpg",
      "userId": "101017276597517313247"
     },
     "user_tz": 300
    },
    "id": "l3WQMGZKG49o",
    "outputId": "7a4f93fb-88f2-40d7-8e28-92af15daeb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'userId', u'movieId', u'rating', u'timestamp'], dtype='object')\n",
      "10000131\n"
     ]
    }
   ],
   "source": [
    "testDf = pd.read_csv('processed/test.csv')\n",
    "R_test = buildRatingsMatrix(testDf, movieDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 13281,
     "status": "ok",
     "timestamp": 1519282624431,
     "user": {
      "displayName": "Shreyas Mundhra",
      "photoUrl": "//lh6.googleusercontent.com/-NAxZtDWd8Qw/AAAAAAAAAAI/AAAAAAAAABM/wJAT8GNp7hg/s50-c-k-no/photo.jpg",
      "userId": "101017276597517313247"
     },
     "user_tz": 300
    },
    "id": "g613Gm7PWFMP",
    "outputId": "fa1c57a0-f6e6-46d6-9753-9a0734280ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test rmse: ', 0.8991843561757922)\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Test rmse: \", findRMSE(R_test, V, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rating Matrix shape: ', (138494, 26745))\n",
      "('User id: ', 20000)\n",
      "('MRR: ', 0.0014721004876985387)\n",
      "('User id: ', 40000)\n",
      "('MRR: ', 0.001461298352154925)\n",
      "('User id: ', 60000)\n",
      "('MRR: ', 0.0014485085738971488)\n",
      "('User id: ', 80000)\n",
      "('MRR: ', 0.001434079726996797)\n",
      "('User id: ', 100000)\n",
      "('MRR: ', 0.0014388180353729094)\n",
      "('User id: ', 120000)\n",
      "('MRR: ', 0.001439528230753022)\n",
      "('MRR: ', 0.0014466085492235278)\n",
      "Wall time: 6min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mrr = findMRR(R_test, testDf, V, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**The format for presenting the results is as shown below:**\n",
    "<br>\n",
    "**[params] - cost, rmse, mrr**\n",
    "<br>\n",
    "<br>\n",
    "**The results for different parameters are as shown below:**\n",
    "<br>\n",
    "alpha=0.02, lambda=0.05, epochs=4, rank=8 - 35716.07382967673, 0.937433774076947, 0.0016055583979725132\n",
    "<br>\n",
    "alpha=0.02, lambda=0.05, epochs=5, rank=8 - 36569.29635013777, 0.8991843561757922, 0.0014466085492235278\n",
    "<br>\n",
    "<br>\n",
    "alpha=0.02, lambda=0.05, epochs=3, rank=6 - 57956.23828272209, 2.3831375938103045, 0.00031533441247997315\n",
    "<br>\n",
    "alpha=0.02, lambda=0.05, epochs=3, rank=8 - 64802.70846971691, 2.1481592303174124, 0.00024105607546223403\n",
    "<br>\n",
    "alpha=0.02, lambda=0.05, epochs=3, rank=10 - 73383.93550978332, 2.2577263788179387, 0.00021896018357628571\n",
    "<br>\n",
    "alpha=0.02, lambda=0.05, epochs=3, rank=12 - 78496.42261932473, 1.722586040283862, 0.00019679348599852103\n",
    "<br>\n",
    "alpha=0.02, lambda=0.05, epochs=3, rank=14 - 86365.03847632423, 1.769643054603345, 0.0001635216989103651\n",
    "<br>\n",
    "<br>\n",
    "alpha=0.02, lambda=0.03, epochs=3, rank=12 - 51898.65484773593, 1.80567572792333, 0.0002782428808433028\n",
    "<br>\n",
    "alpha=0.02, lambda=0.06, epochs=3, rank=12 - 91243.59263266146, 1.6540362682154743, 0.00020567054655245604\n",
    "<br>\n",
    "alpha=0.02, lambda=0.07, epochs=3, rank=12 - 101825.6501196088, 1.4577480021398017, 0.0002127411669789362\n",
    "<br>\n",
    "alpha=0.02, lambda=0.08, epochs=3, rank=12 - 114734.08176509904, 1.8308525526425596, 0.00023944179999416633\n",
    "<br>\n",
    "<br>\n",
    "alpha=0.01, lambda=0.07, epochs=3, rank=12 - 116822.95796665098, 1.9511333472712422, 0.00020466758972919683\n",
    "<br>\n",
    "alpha=0.015, lambda=0.07, epochs=3, rank=12 - 111242.52258992748, 2.3667979083432162, 0.00018848672450557549\n",
    "<br>\n",
    "alpha=0.025, lambda=0.07, epochs=3, rank=12 - 97016.95650144889, 1.4949732339925546, 0.00018760914758979196\n",
    "<br>\n",
    "alpha=0.03, lambda=0.07, epochs=3, rank=12 - 95808.92566118314, 2.090566906821871, 0.00020254878287447923\n",
    "<br>\n",
    "<br>\n",
    "alpha=0.02, lambda=0.07, epochs=8, rank=12 - 81004.78937769009, 1.0790033312432232, 0.0002654475673025698"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "train.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
